{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CEh-xw8UsEa6"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "class SGD():\n",
        "    def __init__(self, alpha=0.5, n_iters=1000):\n",
        "      self.b = None\n",
        "      self._alpha = alpha\n",
        "      self._n_iters = n_iters\n",
        "    def gradient_step(self, b, b_grad):\n",
        "      return b - self._alpha * b_grad\n",
        "    def optimize(self, X, y, start_b, n_iters):\n",
        "      b = start_b.copy()\n",
        "      for i in range(n_iters):\n",
        "          b_grad = self.grad_func(X, y, b)\n",
        "          b = self.gradient_step(b, b_grad)\n",
        "      return b\n",
        "    def fit(self, X, y):\n",
        "      m = X.shape[1]\n",
        "      start_b = np.ones(m)\n",
        "      self.b = self.optimize(X, y, start_b, self._n_iters)\n",
        "class LogReg(SGD):\n",
        "    def sigmoid(self, X, b):\n",
        "      return 1. / (1. + np.exp(-X.dot(b)))\n",
        "    def grad_func(self, X, y, b):\n",
        "      n = X.shape[0]\n",
        "      grad = 1. / n * X.transpose().dot(self.sigmoid(X, b) - y)\n",
        "      return grad\n",
        "    def predict_proba(self, X):\n",
        "      return self.sigmoid(X, self.b)\n",
        "    def predict(self, X):\n",
        "      y_pred = self.predict_proba(X) > 0.5\n",
        "      return y_pred"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Выведите результаты работы библиотечной модели - в численном и в графическом виде."
      ],
      "metadata": {
        "id": "n57Om34dxGds"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "from sklearn.datasets import make_classification\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "X,y = make_classification (n_samples=1000,\n",
        "                          n_features=2,\n",
        "                          n_informative=2,\n",
        "                          n_redundant=0,\n",
        "                          n_classes=2,\n",
        "                          class_sep=2,\n",
        "                          random_state=1)\n",
        "\n",
        "model = LogisticRegression()\n",
        "model.fit(X, y)\n",
        "\n",
        "y_pred = model.predict(X)\n",
        "accuracy = accuracy_score(y, y_pred)\n",
        "f1 = f1_score(y, y_pred)\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.scatter(X[:, 0], X[:, 1], c=y)\n",
        "\n",
        "slope = -(model.coef_[0][0] / model.coef_[0][1])\n",
        "intercept = -(model.intercept_ / model.coef_[0][1])\n",
        "x_values = np.linspace(X[:, 0].min(), X[:, 0].max())\n",
        "y_values = slope * x_values + intercept\n",
        "plt.plot(x_values, y_values, color='red')\n",
        "\n",
        "plt.xlabel('Feature 1')\n",
        "plt.ylabel('Feature 2')\n",
        "plt.title(f'Logistic Regression Classification\\nAccuracy: {accuracy:.2f}, F1-Score: {f1:.2f}')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "YmgHvHcHxF3t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Проверьте работу модели с другими значениями скорости обучения. Найдите значение, при котором градиентный спуск расходится."
      ],
      "metadata": {
        "id": "KTNkwXhg0TDm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = LogReg(alpha=90, n_iters=1000)\n",
        "print(model.fit(X, y))\n",
        "print('Модель расходится при alpha = 90')"
      ],
      "metadata": {
        "id": "00QpTf4ty8w5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Модифицируйте код модели таким образом, чтобы фиктивный столбец единиц добавлялся к матрице признаков внутри класса."
      ],
      "metadata": {
        "id": "17xIwxnV0XfV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class LogRegModified(SGD):\n",
        "    def sigmoid(self, X, b):\n",
        "        return 1. / (1. + np.exp(-X.dot(b)))\n",
        "\n",
        "    def grad_func(self, X, y, b):\n",
        "        n = X.shape[0]\n",
        "        grad = 1. / n * X.transpose().dot(self.sigmoid(X, b) - y)\n",
        "        return grad\n",
        "\n",
        "    def predict_proba(self, X):\n",
        "        X_with_bias = np.c_[np.ones(X.shape[0]), X]\n",
        "        return self.sigmoid(X_with_bias, self.b)\n",
        "\n",
        "    def predict(self, X):\n",
        "        y_pred = self.predict_proba(X) > 0.5\n",
        "        return y_pred.astype(int)\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        X_with_bias = np.c_[np.ones(X.shape[0]), X]\n",
        "        m = X_with_bias.shape[1]\n",
        "        start_b = np.zeros(m)\n",
        "        self.b = self.optimize(X_with_bias, y, start_b, self._n_iters)"
      ],
      "metadata": {
        "id": "0hoMMApR0IqR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Поэкспериментируйте с разными значениями параметра class_sep при генерации датасета. Визуализируйте полученные распределения. Сделайте вывод о том, как этот параметр влияет на точность получаемых моделей."
      ],
      "metadata": {
        "id": "SK9lHKtF147z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class_seps = [0.5, 1, 2]\n",
        "accuracies = []\n",
        "\n",
        "plt.figure(figsize=(18, 6))\n",
        "\n",
        "for i, class_sep in enumerate(class_seps):\n",
        "    X,y = make_classification (n_samples=1000,\n",
        "                          n_features=2,\n",
        "                          n_informative=2,\n",
        "                          n_redundant=0,\n",
        "                          n_classes=2,\n",
        "                          class_sep=class_sep,\n",
        "                          random_state=1)\n",
        "\n",
        "    model = LogRegModified(alpha=0.5, n_iters=1000)\n",
        "    model.fit(X, y)\n",
        "\n",
        "    y_pred = model.predict(X)\n",
        "    accuracy = accuracy_score(y, y_pred)\n",
        "    accuracies.append(accuracy)\n",
        "\n",
        "    plt.subplot(1, len(class_seps), i + 1)\n",
        "    plt.scatter(X[:, 0], X[:, 1], c=y, cmap='winter', edgecolor='k', s=50)\n",
        "    plt.title(f'class_sep={class_sep}, Accuracy: {accuracy:.2f}')\n",
        "    plt.xlabel('Feature 1')\n",
        "    plt.ylabel('Feature 2')\n",
        "\n",
        "plt.suptitle('Logistic Regression with Different class_sep Values')\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "_PFepOdA0wZt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "при увеличении параметра class_sep данные становятся более различимыми и точность классификации увеличивается"
      ],
      "metadata": {
        "id": "6iEvRaij1Gfv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Сгенерируйте датасет с большим числом признаков и примените к нему созданную модель."
      ],
      "metadata": {
        "id": "kHKxa4x62unM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_large,y_large= make_classification (n_samples=1000,\n",
        "                          n_features=20,\n",
        "                          n_informative=2,\n",
        "                          n_redundant=0,\n",
        "                          n_classes=2,\n",
        "                          class_sep=1,\n",
        "                          random_state=1)\n",
        "\n",
        "model_large = LogRegModified(alpha=0.5, n_iters=1000)\n",
        "model_large.fit(X_large, y_large)\n",
        "\n",
        "y_pred_large = model_large.predict(X_large)\n",
        "accuracy_large = accuracy_score(y_large, y_pred_large)\n",
        "\n",
        "accuracy_large\n"
      ],
      "metadata": {
        "id": "iEFuok2C2aVB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Сгенерируйте датасет с большим количеством классов и реализуйте в классе алгоритм \"один против всех\". Решите задачу множественной классификации средствами sklearn."
      ],
      "metadata": {
        "id": "YRHqebJj3AZW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.multiclass import OneVsRestClassifier\n",
        "\n",
        "X_multi,y_multi= make_classification (n_samples=1000,\n",
        "                          n_features=10,\n",
        "                          n_informative=5,\n",
        "                          n_redundant=0,\n",
        "                          n_classes=3,\n",
        "                          class_sep=1,\n",
        "                          random_state=1)\n",
        "\n",
        "ovr_classifier = OneVsRestClassifier(LogisticRegression())\n",
        "ovr_classifier.fit(X_multi, y_multi)\n",
        "\n",
        "y_pred_multi = ovr_classifier.predict(X_multi)\n",
        "accuracy_multi = accuracy_score(y_multi, y_pred_multi)\n",
        "\n",
        "accuracy_multi"
      ],
      "metadata": {
        "id": "ajXLuN_p3Ai-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Выведите значения вероятностей для каждого объекта принадлежать тому или иному классу для библиотечной модели LogisticRegression."
      ],
      "metadata": {
        "id": "ELfT89B0382J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "probabilities = ovr_classifier.predict_proba(X_multi)\n",
        "probabilities"
      ],
      "metadata": {
        "id": "UwJtGK8L39jm"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}